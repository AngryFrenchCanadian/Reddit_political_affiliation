{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd\n",
    "from psaw import PushshiftAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving info w environment variables\n",
    "USERNAME = os.environ.get('REDDIT_NLP_USERNAME')\n",
    "PASSWORD = os.environ.get('REDDIT_NLP_PASSWORD')\n",
    "CLIENT_ID = os.environ.get('REDDIT_NLP_CLIENT_ID')\n",
    "CLIENT_SECRET = os.environ.get('REDDIT_NLP_SECRET')\n",
    "TARGET_SUBREDDIT_NAME = 'worldnews'\n",
    "\n",
    "# REPUBLICAN SUBREDDITS LIST :  r/conservative r/republican "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit= praw.Reddit(user_agent='Comment Extraction (by u/Reddit_nlp_pa)',\n",
    "                    client_id=CLIENT_ID, client_secret=CLIENT_SECRET,\n",
    "                    username=USERNAME, password=PASSWORD)\n",
    "# max_results_per_request necessary due to bug\n",
    "api = PushshiftAPI(reddit,max_results_per_request=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldnews\n"
     ]
    }
   ],
   "source": [
    "#testing praw\n",
    "subreddit = reddit.subreddit(TARGET_SUBREDDIT_NAME)\n",
    "print(subreddit.display_name)  # Output: worldnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "POST_FILENAME = 'filtered_republican_posts.csv'\n",
    "filtered_posts = pd.read_csv(POST_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullnames = list(filtered_posts['fullname'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2142"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 posts parsed. Elapsed time: 277.01581835746765\n",
      "\tCurrent comment count: 17652\n",
      "200 posts parsed. Elapsed time: 619.0872783660889\n",
      "\tCurrent comment count: 37429\n",
      "300 posts parsed. Elapsed time: 977.0248873233795\n",
      "\tCurrent comment count: 57148\n",
      "400 posts parsed. Elapsed time: 1334.4629926681519\n",
      "\tCurrent comment count: 77683\n",
      "500 posts parsed. Elapsed time: 1807.171565771103\n",
      "\tCurrent comment count: 99635\n",
      "600 posts parsed. Elapsed time: 2155.6665120124817\n",
      "\tCurrent comment count: 119997\n",
      "700 posts parsed. Elapsed time: 2681.137781381607\n",
      "\tCurrent comment count: 142278\n",
      "800 posts parsed. Elapsed time: 3025.9003767967224\n",
      "\tCurrent comment count: 161540\n",
      "900 posts parsed. Elapsed time: 3350.7395780086517\n",
      "\tCurrent comment count: 182519\n",
      "1000 posts parsed. Elapsed time: 3631.049623966217\n",
      "\tCurrent comment count: 202594\n",
      "1100 posts parsed. Elapsed time: 3977.894493818283\n",
      "\tCurrent comment count: 222950\n",
      "1200 posts parsed. Elapsed time: 4332.379896640778\n",
      "\tCurrent comment count: 243335\n",
      "1300 posts parsed. Elapsed time: 4652.099874258041\n",
      "\tCurrent comment count: 262961\n",
      "1400 posts parsed. Elapsed time: 4914.440860509872\n",
      "\tCurrent comment count: 280884\n",
      "1500 posts parsed. Elapsed time: 5565.119027376175\n",
      "\tCurrent comment count: 301184\n",
      "1600 posts parsed. Elapsed time: 5825.8807508945465\n",
      "\tCurrent comment count: 317966\n",
      "1700 posts parsed. Elapsed time: 6112.031394481659\n",
      "\tCurrent comment count: 334432\n",
      "1800 posts parsed. Elapsed time: 6894.983798265457\n",
      "\tCurrent comment count: 353375\n",
      "1900 posts parsed. Elapsed time: 7154.996006011963\n",
      "\tCurrent comment count: 369727\n",
      "2000 posts parsed. Elapsed time: 7403.910977125168\n",
      "\tCurrent comment count: 385955\n",
      "2100 posts parsed. Elapsed time: 8171.798876523972\n",
      "\tCurrent comment count: 407461\n"
     ]
    }
   ],
   "source": [
    "#fetching all comments from every post in the filtered list\n",
    "\n",
    "OUTPUT_FILENAME = 'republican_comments_raw.csv'\n",
    "\n",
    "comment_f_start = time.time()\n",
    "\n",
    "subreddit_comments = []\n",
    "index =0\n",
    "for post in reddit.info(fullnames):\n",
    "    current_comments = post.comments\n",
    "    current_comments.replace_more(limit=None)\n",
    "    current_comments_list = current_comments.list()\n",
    "    \n",
    "    #merging current comments with master comment list\n",
    "    subreddit_comments += current_comments_list\n",
    "    index += 1\n",
    "    if index % 100 == 0:\n",
    "        current_time = time.time()\n",
    "        print(f'{index} posts parsed. Elapsed time: {current_time-comment_f_start}')\n",
    "        print(f'\\tCurrent comment count: {len(subreddit_comments)}')\n",
    "        \n",
    "        #making backup\n",
    "        raw_comments_df = pd.DataFrame([[c.author, c.body, c.score, c.subreddit, c.created_utc, c.id, c.submission.title, c.submission.id]  for c in subreddit_comments])\n",
    "        raw_comments_df.rename(columns={0: 'author', 1: 'body', 2: 'score', 3: 'subreddit', 4: 'created', 5: 'id', 6: 'post', 7: 'post_title'})\n",
    "        raw_comments_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "    \n",
    "\n",
    "# saving at the end\n",
    "raw_comments_df = pd.DataFrame([[c.author, c.body, c.score, c.subreddit, c.created_utc, c.id, c.submission.title, c.submission.id]  for c in subreddit_comments])\n",
    "raw_comments_df.rename(columns={0: 'author', 1: 'body', 2: 'score', 3: 'subreddit', 4: 'created', 5: 'id', 6: 'post', 7: 'post_title'})\n",
    "raw_comments_df.to_csv(OUTPUT_FILENAME, index=False)      \n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
