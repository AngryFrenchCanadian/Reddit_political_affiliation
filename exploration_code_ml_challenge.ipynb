{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import commentsFilter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss,confusion_matrix, f1_score\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import sparse\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer('english')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = './Data/'\n",
    "# SUBREDDIT = 'r_republican'\n",
    "FILE_NAME = './Data/republican_democrats_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302932, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Created</th>\n",
       "      <th>Id</th>\n",
       "      <th>Post</th>\n",
       "      <th>Post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5th_Law_of_Robotics</td>\n",
       "      <td>It would take him an hour to work his way thro...</td>\n",
       "      <td>1</td>\n",
       "      <td>democrats</td>\n",
       "      <td>1600191390</td>\n",
       "      <td>g5dngzh</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupanudles</td>\n",
       "      <td>Hahahahahahahahahahahahahahahahahaha</td>\n",
       "      <td>1</td>\n",
       "      <td>democrats</td>\n",
       "      <td>1600191448</td>\n",
       "      <td>g5dnm3c</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89SC</td>\n",
       "      <td>He couldn’t even make it through the SparkNote...</td>\n",
       "      <td>1</td>\n",
       "      <td>democrats</td>\n",
       "      <td>1600191720</td>\n",
       "      <td>g5do9pg</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XAfricaSaltX</td>\n",
       "      <td>Suuuuuuuuuuuure</td>\n",
       "      <td>1</td>\n",
       "      <td>democrats</td>\n",
       "      <td>1600193029</td>\n",
       "      <td>g5drd0e</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donaldtrumpsmushroom</td>\n",
       "      <td>If he reads with his bunghole, sure.</td>\n",
       "      <td>1</td>\n",
       "      <td>democrats</td>\n",
       "      <td>1600195657</td>\n",
       "      <td>g5dxn0n</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author                                               Body  \\\n",
       "0   5th_Law_of_Robotics  It would take him an hour to work his way thro...   \n",
       "1            Cupanudles               Hahahahahahahahahahahahahahahahahaha   \n",
       "2                  89SC  He couldn’t even make it through the SparkNote...   \n",
       "3          XAfricaSaltX                                    Suuuuuuuuuuuure   \n",
       "4  Donaldtrumpsmushroom               If he reads with his bunghole, sure.   \n",
       "\n",
       "   Score  Subreddit     Created       Id  \\\n",
       "0      1  democrats  1600191390  g5dngzh   \n",
       "1      1  democrats  1600191448  g5dnm3c   \n",
       "2      1  democrats  1600191720  g5do9pg   \n",
       "3      1  democrats  1600193029  g5drd0e   \n",
       "4      1  democrats  1600195657  g5dxn0n   \n",
       "\n",
       "                                                Post Post_id  \n",
       "0  Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "1  Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "2  Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "3  Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "4  Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(FILE_NAME, index_col=0)\n",
    "df['Score'].astype(np.int32)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cl = data[data['Score'] > 30]\n",
    "# df_ng = data[data['Score'] < -10]\n",
    "# df = pd.concat([df_cl, df_ng])\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting subreddit vals to ints\n",
    "\n",
    "index_democrat = df[df['Subreddit'] == 'democrats'].index\n",
    "df['Subreddit'] =0 \n",
    "df.loc[index_democrat, 'Subreddit'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Created</th>\n",
       "      <th>Id</th>\n",
       "      <th>Post</th>\n",
       "      <th>Post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5th_Law_of_Robotics</td>\n",
       "      <td>It would take him an hour to work his way thro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600191390</td>\n",
       "      <td>g5dngzh</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cupanudles</td>\n",
       "      <td>Hahahahahahahahahahahahahahahahahaha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600191448</td>\n",
       "      <td>g5dnm3c</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>89SC</td>\n",
       "      <td>He couldn’t even make it through the SparkNote...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600191720</td>\n",
       "      <td>g5do9pg</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>XAfricaSaltX</td>\n",
       "      <td>Suuuuuuuuuuuure</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600193029</td>\n",
       "      <td>g5drd0e</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Donaldtrumpsmushroom</td>\n",
       "      <td>If he reads with his bunghole, sure.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600195657</td>\n",
       "      <td>g5dxn0n</td>\n",
       "      <td>Noted Bibliophobe Donald Trump Claims He Read ...</td>\n",
       "      <td>itdjfm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145551</th>\n",
       "      <td>145551</td>\n",
       "      <td>softwaredev</td>\n",
       "      <td>&gt;  it's ads you CHOSE to watch\\n\\nReally? peop...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1483677072</td>\n",
       "      <td>dc2bbs7</td>\n",
       "      <td>January Begins Roundtable</td>\n",
       "      <td>5lfpmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145552</th>\n",
       "      <td>145552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Obama had charisma AND inspired a lot of peopl...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1483510589</td>\n",
       "      <td>dbz80jq</td>\n",
       "      <td>January Begins Roundtable</td>\n",
       "      <td>5lfpmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145553</th>\n",
       "      <td>145553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt; Really? people get to CHOOSE the ads nowaday...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1483690774</td>\n",
       "      <td>dc2i8vo</td>\n",
       "      <td>January Begins Roundtable</td>\n",
       "      <td>5lfpmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145554</th>\n",
       "      <td>145554</td>\n",
       "      <td>softwaredev</td>\n",
       "      <td>&gt; If you look at all her ads ...\\n\\nThe point ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1483779412</td>\n",
       "      <td>dc42r8t</td>\n",
       "      <td>January Begins Roundtable</td>\n",
       "      <td>5lfpmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145555</th>\n",
       "      <td>145555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt; You are the one who from my point of view is...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1484187910</td>\n",
       "      <td>dcbc5b1</td>\n",
       "      <td>January Begins Roundtable</td>\n",
       "      <td>5lfpmc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145556 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                Author  \\\n",
       "0                0   5th_Law_of_Robotics   \n",
       "1                1            Cupanudles   \n",
       "2                2                  89SC   \n",
       "3                3          XAfricaSaltX   \n",
       "4                4  Donaldtrumpsmushroom   \n",
       "...            ...                   ...   \n",
       "145551      145551           softwaredev   \n",
       "145552      145552                   NaN   \n",
       "145553      145553                   NaN   \n",
       "145554      145554           softwaredev   \n",
       "145555      145555                   NaN   \n",
       "\n",
       "                                                     Body  Score  Subreddit  \\\n",
       "0       It would take him an hour to work his way thro...      1          1   \n",
       "1                    Hahahahahahahahahahahahahahahahahaha      1          1   \n",
       "2       He couldn’t even make it through the SparkNote...      1          1   \n",
       "3                                         Suuuuuuuuuuuure      1          1   \n",
       "4                    If he reads with his bunghole, sure.      1          1   \n",
       "...                                                   ...    ...        ...   \n",
       "145551  >  it's ads you CHOSE to watch\\n\\nReally? peop...      2          1   \n",
       "145552  Obama had charisma AND inspired a lot of peopl...      2          1   \n",
       "145553  > Really? people get to CHOOSE the ads nowaday...      1          1   \n",
       "145554  > If you look at all her ads ...\\n\\nThe point ...      2          1   \n",
       "145555  > You are the one who from my point of view is...      1          1   \n",
       "\n",
       "           Created       Id  \\\n",
       "0       1600191390  g5dngzh   \n",
       "1       1600191448  g5dnm3c   \n",
       "2       1600191720  g5do9pg   \n",
       "3       1600193029  g5drd0e   \n",
       "4       1600195657  g5dxn0n   \n",
       "...            ...      ...   \n",
       "145551  1483677072  dc2bbs7   \n",
       "145552  1483510589  dbz80jq   \n",
       "145553  1483690774  dc2i8vo   \n",
       "145554  1483779412  dc42r8t   \n",
       "145555  1484187910  dcbc5b1   \n",
       "\n",
       "                                                     Post Post_id  \n",
       "0       Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "1       Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "2       Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "3       Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "4       Noted Bibliophobe Donald Trump Claims He Read ...  itdjfm  \n",
       "...                                                   ...     ...  \n",
       "145551                          January Begins Roundtable  5lfpmc  \n",
       "145552                          January Begins Roundtable  5lfpmc  \n",
       "145553                          January Begins Roundtable  5lfpmc  \n",
       "145554                          January Begins Roundtable  5lfpmc  \n",
       "145555                          January Begins Roundtable  5lfpmc  \n",
       "\n",
       "[145556 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Subreddit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automod indexes: Int64Index([   114,    197,    748,    931,    946,   1100,   1101,   1158,\n",
      "              1240,   1246,\n",
      "            ...\n",
      "            285696, 285771, 285811, 285871, 285898, 285962, 286035, 286060,\n",
      "            286068, 288070],\n",
      "           dtype='int64', length=7424)\n",
      "Deleted/removed comments indexes: Int64Index([    27,     51,     52,     74,     75,     89,     93,     95,\n",
      "               113,    158,\n",
      "            ...\n",
      "            302678, 302714, 302748, 302751, 302758, 302764, 302823, 302837,\n",
      "            302852, 302889],\n",
      "           dtype='int64', length=22198)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(273310, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering \n",
    "# removing comments from automod, removed comments, comments with a neutral score \n",
    "# filterComments(df, filter_automod, filter_negative_comments, filter_deleted_posts, filter_neutral_comments):\n",
    "commentsFilter.filterComments(df, 1, 0, 1, 0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adding a column with negativ score label\n",
    "\n",
    "# df['pos_score'] =0\n",
    "# index_pos_score = df[df['Score'] >= 1].index\n",
    "# df.loc[index_pos_score, 'pos_score'] =1\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    It would take him an hour to work his way thro...\n",
       "1                 Hahahahahahahahahahahahahahahahahaha\n",
       "2    He couldn’t even make it through the SparkNote...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coverting column to str (incase a comment contains only digits and is considered int)\n",
    "df['Body'] = df['Body'].astype(str)\n",
    "df['Body'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-340738f988c8>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-340738f988c8>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    xtr, xts, ytr, yts = train_test_split(x, y, test _size=0.30, stratify=y)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data\n",
    "x = df['Body', 'Score']\n",
    "y = df['Subreddit']\n",
    "xtr, xts, ytr, yts = train_test_split(x, y, test _size=0.30, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # random undersampling for class with negative score for training set\n",
    "# pos_class_count, neg_class_count = ytr.value_counts()\n",
    "# xtrain = pd.concat([xtr, ytr], axis=1)\n",
    "\n",
    "# xtrain.columns\n",
    "# xtr_pos= xtrain[xtrain['pos_score'] ==1]\n",
    "# xtr_neg = xtrain[xtrain['pos_score']==0]\n",
    "\n",
    "# xtr_pos_under = xtr_pos.sample(neg_class_count)\n",
    "# xtrain = pd.concat([xtr_pos_under, xtr_neg])\n",
    "# xtr = xtrain['Body']\n",
    "# ytr = xtrain['pos_score']\n",
    "# print(f'xtr shape: {xtr.shape}  ytr shape: {ytr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pipeline params:\n",
    "    text\n",
    "    remove_stopwords --> [0,1] \n",
    "    enable_stemming --> [0, 1]\n",
    "    n_gram   1-5 maybe? [0, 4]\n",
    "    tokenizer  --> only nltk.word_tokenize for now\n",
    "    tf_idf/ embeddi --> only tf_idf for now\n",
    "\"\"\"\n",
    "\n",
    "def nlp_pipeline(text, remove_stopwords, enable_stemming, n_gram, tokenizer ):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def stemming_tokenizer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words_list]\n",
    "    lems = [wnl.lemmatize(w) for w in filtered_tokens]\n",
    "    #removing punctuatoin\n",
    "    new_words= [word for word in lems if word.isalnum()]\n",
    "    return new_words\n",
    "    \n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(w) for w in tokens]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [w for w in tokens if not w in stop_words_list]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# converting comments to lowercase\n",
    "xtr_comments = xtr.str.lower()\n",
    "xts_comments = xts.str.lower()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=20000, tokenizer=stemming_tokenizer, ngram_range=(1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# tfidf\n",
    "xtr_vect = tfidf.fit_transform(xtr_comments)\n",
    "xts_vect = tfidf.fit_transform(xts_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horribl idea\n",
    "from scipy import sparse\n",
    "nRow_xtr = xtr_vect.shape[0]\n",
    "nRow_xts = xts_vect.shape[0]\n",
    "\n",
    "xtr_score_csr = sparse.csr_matrix(xtr['Score'].to_numpy()).reshape(nRow_xtr, 1)\n",
    "xts_score_csr = sparse.csr_matrix(xts['Score'].to_numpy()).reshape(nRow_xts, 1)\n",
    "\n",
    "xtr_sm = sparse.hstack([xtr_vect, xtr_score_csr])\n",
    "xts_sm = sparse.hstack([xts_vect, xts_score_csr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import coo_matrix, hstack\n",
    "# bsbsbs = xtr['Score'].values\n",
    "# bsbsbs.shape\n",
    "# bs = sparse.hstack((xtr_vec, bsbsbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regresssion\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=20000, class_weight={1:1})\n",
    "lr.fit(xtr_sm, ytr)\n",
    "pred = lr.predict(xts_sm)\n",
    "\n",
    "print('\\nConfusion matrix\\n',confusion_matrix(yts, pred))\n",
    "print(f'f1 score: {f1_score(yts, pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# nn = MLPClassifier(random_state=1, max_iter=300)\n",
    "# nn.fit(xtr_vect, ytr)\n",
    "# preds = nn.predict(xts_vect)\n",
    "# pred_probas= nn.predict_proba(xts_vect)\n",
    "\n",
    "# print('\\nConfusion matrix\\n',confusion_matrix(yts, preds))\n",
    "# print(f'f1 score: {f1_score(yts, pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
